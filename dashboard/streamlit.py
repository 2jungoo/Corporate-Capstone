import streamlit as st
import pandas as pd
import sqlalchemy as sa
import requests
from datetime import datetime
import plotly.express as px
import numpy as np
import os
import joblib
import json
import os
import warnings
import numpy as np
from datetime import datetime, timedelta
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

target_weight = 116 # (ëŒ€ì‹œë³´ë“œ ê¸°ì¤€ 80kgë¡œ ìˆ˜ì •)

# 1. ì²´ì¤‘(kg)ëŒ€ë³„ ì •ìƒ ì²´ì˜¨(Â°C) ë²”ìœ„ ê·œì¹™
HEALTH_RULES = [
    (0, 30, 38.0, 39.9),   # 0-30kg : 38.7Â°C ~ 39.9Â°C
    (30, 70, 37.9, 39.8),  # 30-70kg: 38.6Â°C ~ 39.8Â°C
    (70, 1e9, 37.8, 39.7)  # 70kg+  : 38.5Â°C ~ 39.7Â°C
]

# 2. ì²´ì¤‘(w)ì„ ë°›ì•„, ì •ìƒ ë²”ìœ„(tmin, tmax)ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
def get_normal_temp_range(w):
    if pd.isna(w) or w <= 0: # ì²´ì¤‘ê°’ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ë°˜í™˜
        return 38.6, 39.8
    for lo, hi, tmin, tmax in HEALTH_RULES:
        if lo <= w < hi:
            return tmin, tmax
    return 38.6, 39.8 # (ê¸°ë³¸ê°’)

class DummyDataGenerator:
    def __init__(self, pattern_file='./models/growth_patterns_ai.json'):
        self.pattern_file = pattern_file
        self.target_weight = target_weight
        self.patterns = None
        self.load_patterns()

    def load_patterns(self):
        print("\n" + "=" * 80)
        print("í•™ìŠµëœ íŒ¨í„´ ë¡œë”© ì¤‘...")
        print("=" * 80)
        if not os.path.exists(self.pattern_file):
            print("íŒ¨í„´ íŒŒì¼ì´ ì—†ì–´ ê¸°ë³¸ê°’ ì‚¬ìš©")
            self.patterns = self.get_default_patterns()
        else:
            with open(self.pattern_file, 'r', encoding='utf-8') as f:
                self.patterns = json.load(f)
        print("íŒ¨í„´ ë¡œë“œ ì™„ë£Œ")
        return self.patterns

    def get_default_patterns(self):
        return {
            'overall': {
                'mean_daily_gain': 0.65,
                'std_daily_gain': 0.15,
                'min_weight': 20.0,
                'max_weight': 110.0
            },
            'weight_bins': {
                '0-20kg': {'mean_daily_gain': 0.45, 'std_daily_gain': 0.10},
                '20-40kg': {'mean_daily_gain': 0.65, 'std_daily_gain': 0.12},
                '40-60kg': {'mean_daily_gain': 0.75, 'std_daily_gain': 0.10},
                '60-80kg': {'mean_daily_gain': 0.80, 'std_daily_gain': 0.10},
                '80-100kg': {'mean_daily_gain': 0.70, 'std_daily_gain': 0.12},
                '100kg+': {'mean_daily_gain': 0.55, 'std_daily_gain': 0.15}
            }
        }

    def get_daily_gain_for_weight(self, weight, day):
        weight_bins = {
            '0-20kg': (0, 20), '20-40kg': (20, 40), '40-60kg': (40, 60),
            '60-80kg': (60, 80), '80-100kg': (80, 100), '100kg+': (100, 200)
        }
        for bin_name, (min_w, max_w) in weight_bins.items():
            if min_w <= weight < max_w:
                if bin_name in self.patterns['weight_bins']:
                    bin_data = self.patterns['weight_bins'][bin_name]
                    mean_gain = bin_data['mean_daily_gain']
                    std_gain = bin_data.get('std_daily_gain', mean_gain * 0.15)
                    daily_gain = np.random.normal(mean_gain, std_gain * 0.3)
                    growth_factor = 1.0
                    if day < 30:
                        growth_factor = 0.7 + (day / 30) * 0.3
                    elif day > 120:
                        growth_factor = max(0.6, 1.0 - (day - 120) / 200)
                    daily_gain *= growth_factor
                    daily_gain = np.clip(daily_gain, 0.2, 1.2)
                    return daily_gain
        return 0.6

    def generate_pig_data(self, pig_id, start_weight=None, n_days=60):
        if start_weight is None:
            start_weight = np.random.uniform(20, 30)
        data = []
        current_weight = start_weight
        for day in range(n_days):
            daily_gain = self.get_daily_gain_for_weight(current_weight, day)
            current_weight = current_weight + abs(daily_gain)
            measured_weight = current_weight + np.random.normal(0, 0.1)
            feed_intake = current_weight * 0.035 * np.random.uniform(0.95, 1.05)
            feed_intake = max(0.5, feed_intake)
            data.append({
                'pig_id': pig_id,
                'day': day,
                'weight_kg': round(measured_weight, 2),
                'daily_gain_kg': round(daily_gain, 3),
                'feed_intake_kg': round(feed_intake, 2),
                'temperature_c': round(22 + np.random.normal(0, 2), 1),
                'humidity_percent': round(65 + np.random.normal(0, 5), 1),
                'date': (datetime.now() + timedelta(days=day)).strftime('%Y-%m-%d')
            })
        return pd.DataFrame(data)

    def generate_dummy_dataset(self, n_pigs=10, n_days=60):
        print(f"\n{n_pigs}ë§ˆë¦¬ ë¼ì§€ {n_days}ì¼ì¹˜ ë”ë¯¸ ë°ì´í„° ìƒì„± ì¤‘...")
        all_data = []
        for pig_id in range(1, n_pigs + 1):
            pig_data = self.generate_pig_data(pig_id, n_days=n_days)
            all_data.append(pig_data)
        dataset = pd.concat(all_data, ignore_index=True)
        print(f"ì´ {len(dataset)}ê±´ ìƒì„± ì™„ë£Œ")
        return dataset


class LSTMPredictor:
    def __init__(self, sequence_length=14):
        self.sequence_length = sequence_length
        self.model = None
        self.scaler = StandardScaler()

    def create_sequences(self, data):
        X, y = [], []
        for i in range(len(data) - self.sequence_length):
            X.append(data[i:i + self.sequence_length])
            y.append(data[i + self.sequence_length, 0])
        return np.array(X), np.array(y)

    def build_model(self, n_features):
        model = keras.Sequential([
            layers.Input(shape=(self.sequence_length, n_features)),
            layers.LSTM(64, return_sequences=True, dropout=0.0, recurrent_dropout=0.0, use_bias=True, unit_forget_bias=True),
            layers.LSTM(32, return_sequences=False, dropout=0.0, recurrent_dropout=0.0, use_bias=True, unit_forget_bias=True),
            layers.Dense(16, activation='relu'),
            layers.Dense(1)
        ])
        model.compile(optimizer='adam', loss='mse', metrics=['mae'])
        return model

    def train(self, df):
        print("\nLSTM ëª¨ë¸ í•™ìŠµ ì¤‘...")
        df = df.copy()
        if 'weight_kg' in df.columns:
            df['weight'] = df['weight_kg']
        if 'feed_intake_kg' in df.columns:
            df['feed'] = df['feed_intake_kg']
        if 'daily_gain_kg' in df.columns:
            df['daily_gain'] = df['daily_gain_kg']
        features = ['weight', 'daily_gain', 'feed']
        missing = [f for f in features if f not in df.columns]
        if missing:
            print(f"í•„ìš”í•œ feature ì—†ìŒ: {missing} - LSTM í•™ìŠµ ê±´ë„ˆëœ€")
            return None
        data_all = df[features].values
        data_scaled_all = self.scaler.fit_transform(data_all)
        df_scaled = df.copy()
        df_scaled[features] = data_scaled_all
        X_list, y_list = [], []
        if 'pig_id' in df_scaled.columns:
            groups = df_scaled.groupby('pig_id', sort=True)
            for _, g in groups:
                arr = g.sort_values('day')[features].values
                if len(arr) > self.sequence_length:
                    Xp, yp = self.create_sequences(arr)
                    if len(Xp) > 0:
                        X_list.append(Xp)
                        y_list.append(yp)
        else:
            Xp, yp = self.create_sequences(df_scaled[features].values)
            if len(Xp) > 0:
                X_list.append(Xp); y_list.append(yp)
        if not X_list:
            print("í•™ìŠµ ë°ì´í„° ë¶€ì¡± - LSTM í•™ìŠµ ê±´ë„ˆëœ€")
            return None
        X = np.concatenate(X_list, axis=0)
        y = np.concatenate(y_list, axis=0)
        self.model = self.build_model(n_features=len(features))
        early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
        history = self.model.fit(
            X, y,
            epochs=50,
            batch_size=16,
            validation_split=0.2,
            callbacks=[early_stop],
            verbose=0
        )
        final_loss = history.history['val_loss'][-1]
        final_mae = history.history['mae'][-1]
        print(f"LSTM í•™ìŠµ ì™„ë£Œ - ValLoss: {final_loss:.4f}, MAE: {final_mae:.4f}")
        return self.model

    def predict_future_weights(self, recent_data, n_days=60):
        if self.model is None:
            return None
        recent_data = recent_data.copy()
        if 'weight_kg' in recent_data.columns:
            recent_data['weight'] = recent_data['weight_kg']
        if 'feed_intake_kg' in recent_data.columns:
            recent_data['feed'] = recent_data['feed_intake_kg']
        if 'daily_gain_kg' in recent_data.columns:
            recent_data['daily_gain'] = recent_data['daily_gain_kg']
        features = ['weight', 'daily_gain', 'feed']
        missing_features = [f for f in features if f not in recent_data.columns]
        if missing_features:
            return None
        data = recent_data[features].values
        if len(data) < self.sequence_length:
            return None
        sequence = data[-self.sequence_length:]
        sequence_scaled = self.scaler.transform(sequence)
        predictions = []
        for _ in range(n_days):
            X_pred = sequence_scaled.reshape(1, self.sequence_length, -1)
            next_weight_scaled = self.model.predict(X_pred, verbose=0)[0, 0]
            temp_data = np.zeros((1, len(features)))
            temp_data[0, 0] = next_weight_scaled
            next_weight = self.scaler.inverse_transform(temp_data)[0, 0]
            predictions.append(next_weight)
            next_daily_gain = next_weight - sequence[-1, 0]
            next_feed = next_weight * 0.035
            next_point = np.array([[next_weight, next_daily_gain, next_feed]])
            next_point_scaled = self.scaler.transform(next_point)
            sequence_scaled = np.vstack([sequence_scaled[1:], next_point_scaled])
            sequence = np.vstack([sequence[1:], next_point])
        return predictions


class AIPredictor:
    def __init__(self, model_dir='./models'):
        self.model_dir = model_dir
        self.rf_model = None
        self.xgb_model = None
        self.rf_scaler = None
        self.load_models()

    def load_models(self):
        print("\nAI ëª¨ë¸ ë¡œë”© ì¤‘...")
        try:
            rf_path = os.path.join(self.model_dir, 'random_forest_model.pkl')
            xgb_path = os.path.join(self.model_dir, 'xgboost_model.pkl')
            scaler_path = os.path.join(self.model_dir, 'random_forest_scaler.pkl')
            if os.path.exists(rf_path):
                self.rf_model = joblib.load(rf_path)
                print("Random Forest ë¡œë“œ")
            if os.path.exists(xgb_path):
                if xgb is not None:
                    self.xgb_model = joblib.load(xgb_path)
                    print("XGBoost ë¡œë“œ")
                else:
                    print("XGBoost ëª¨ë¸ íŒŒì¼ì€ ìˆìœ¼ë‚˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ë¶ˆê°€")
            if os.path.exists(scaler_path):
                self.rf_scaler = joblib.load(scaler_path)
                print("Scaler ë¡œë“œ")
            if self.rf_model is None and self.xgb_model is None:
                print("AI ëª¨ë¸ì´ ì—†ì–´ í†µê³„ ê¸°ë°˜ ì˜ˆì¸¡ ì‚¬ìš©")
        except Exception as e:
            print(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")

    def create_features_for_prediction(self, df):
        df = df.copy()
        df = df.sort_values('day')
        if 'weight_kg' in df.columns:
            df['weight'] = df['weight_kg']
        if 'feed_intake_kg' in df.columns:
            df['feed'] = df['feed_intake_kg']
        df['weight_lag1'] = df['weight'].shift(1)
        df['weight_lag3'] = df['weight'].shift(3)
        df['weight_lag7'] = df['weight'].shift(7)
        df['weight_rolling_mean_7'] = df['weight'].rolling(window=7, min_periods=1).mean()
        df['weight_rolling_std_7'] = df['weight'].rolling(window=7, min_periods=1).std()
        df['weight_change_1d'] = df['weight'] - df['weight_lag1']
        df['weight_change_3d'] = df['weight'] - df['weight_lag3']
        df['weight_change_7d'] = df['weight'] - df['weight_lag7']
        df['feed_weight_ratio'] = df['feed'] / df['weight']
        df['day_squared'] = df['day'] ** 2
        df['weight_squared'] = df['weight'] ** 2
        return df

    def predict_daily_gain(self, pig_data):
        df_features = self.create_features_for_prediction(pig_data)
        df_features = df_features.dropna()
        if len(df_features) == 0:
            return 0.65
        last_row = df_features.iloc[-1:]
        feature_cols = [
            'weight', 'day', 'feed',
            'weight_lag1', 'weight_lag3', 'weight_lag7',
            'weight_rolling_mean_7', 'weight_rolling_std_7',
            'weight_change_1d', 'weight_change_3d', 'weight_change_7d',
            'feed_weight_ratio', 'day_squared', 'weight_squared'
        ]
        X = last_row[feature_cols]
        predictions = []
        if self.rf_model is not None and self.rf_scaler is not None:
            X_scaled = self.rf_scaler.transform(X)
            rf_pred = self.rf_model.predict(X_scaled)[0]
            predictions.append(rf_pred)
        if self.xgb_model is not None:
            xgb_pred = self.xgb_model.predict(X)[0]
            predictions.append(xgb_pred)
        if len(predictions) > 0:
            return np.mean(predictions)
        else:
            return 0.65


class HybridPredictor:
    def __init__(self, target_weight=85):
        self.target_weight = target_weight
        self.ai_predictor = AIPredictor()
        self.lstm_predictor = LSTMPredictor()

    def train_lstm_on_data(self, df_data):
        print("\nLSTM í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì¤‘...")
        all_pig_data = []
        for pig_id in df_data['pig_id'].unique():
            pig_data = df_data[df_data['pig_id'] == pig_id].sort_values('day')
            all_pig_data.append(pig_data)
        combined_data = pd.concat(all_pig_data, ignore_index=True)
        self.lstm_predictor.train(combined_data)

    def predict_shipment(self, df_data):
        print("\nì¶œí•˜ ì‹œì  ì˜ˆì¸¡ ì¤‘...")
        self.train_lstm_on_data(df_data)
        results = []
        for pig_id in df_data['pig_id'].unique():
            pig_data = df_data[df_data['pig_id'] == pig_id].sort_values('day')
            current_weight = pig_data['weight_kg'].iloc[-1]
            current_day = pig_data['day'].iloc[-1]
            start_weight = pig_data['weight_kg'].iloc[0]
            if current_weight >= self.target_weight:
                results.append({
                    'pig_id': pig_id,
                    'current_weight': current_weight,
                    'days_to_shipment': 0,
                    'prediction_method': 'already_ready',
                    'status': 'ready'
                })
                continue
            ai_daily_gain = self.ai_predictor.predict_daily_gain(pig_data)
            remaining_weight = self.target_weight - current_weight
            ai_days = max(1, int(np.ceil(remaining_weight / ai_daily_gain)))
            lstm_predictions = self.lstm_predictor.predict_future_weights(pig_data, n_days=60)
            lstm_days = None
            if lstm_predictions is not None:
                for day, pred_weight in enumerate(lstm_predictions, 1):
                    if pred_weight >= self.target_weight:
                        lstm_days = day
                        break
                if lstm_days is None:
                    lstm_days = 60
            if len(pig_data) >= 7:
                recent_gain = pig_data['daily_gain_kg'].tail(7).mean()
            else:
                recent_gain = pig_data['daily_gain_kg'].mean()

            if recent_gain is None or pd.isna(recent_gain) or recent_gain <= 0.01:
                recent_gain = 0.6
            stat_days = max(1, int(np.ceil(remaining_weight / recent_gain)))
            predictions = []
            weights = []

            predictions.append(ai_days)
            weights.append(0.4)
            if lstm_days is not None:
                predictions.append(lstm_days)
                weights.append(0.4)
            else:
                weights[0] += 0.2
            predictions.append(stat_days)
            weights.append(0.2)
            weights = np.array(weights) / sum(weights)
            final_days = int(np.round(np.average(predictions, weights=weights)))
            min_days = max(1, int(remaining_weight / 1.2))
            max_days = int(remaining_weight / 0.3)
            final_days_clipped = np.clip(final_days, min_days, max_days)
            final_days_int = int(final_days_clipped)
            results.append({
                'pig_id': pig_id,
                'current_day': current_day,
                'current_weight': round(current_weight, 2),
                'start_weight': round(start_weight, 2),
                'remaining_weight': round(remaining_weight, 2),
                'ai_prediction_days': ai_days,
                'lstm_prediction_days': lstm_days if lstm_days else 'N/A',
                'stat_prediction_days': stat_days,
                'final_days_to_shipment': final_days_int,
                'predicted_shipment_date': (datetime.now() + timedelta(days=final_days_int)).strftime('%Y-%m-%d'),
                'prediction_method': 'hybrid_ensemble',
                'ai_daily_gain': round(ai_daily_gain, 3),
                'recent_daily_gain': round(recent_gain, 3),
                'status': 'predicted'
            })
        result_df = pd.DataFrame(results)
        print(f"\nì˜ˆì¸¡ ê²°ê³¼ ìš”ì•½:")
        print(f"- ì¶œí•˜ ì¤€ë¹„ ì™„ë£Œ: {len(result_df[result_df['status'] == 'ready'])}ë§ˆë¦¬")
        print(f"- ì¶œí•˜ ì˜ˆì •: {len(result_df[result_df['status'] == 'predicted'])}ë§ˆë¦¬")
        predicted = result_df[result_df['status'] == 'predicted']
        if len(predicted) > 0:
            print(f"\nì¶œí•˜ ì˜ˆì¸¡:")
            print(f"- í‰ê·  ë‚¨ì€ ê¸°ê°„: {predicted['final_days_to_shipment'].mean():.0f}ì¼")
            print(f"- ìµœë‹¨ ì¶œí•˜: {predicted['final_days_to_shipment'].min():.0f}ì¼ í›„")
            print(f"- ìµœì¥ ì¶œí•˜: {predicted['final_days_to_shipment'].max():.0f}ì¼ í›„")
        return result_df

    def visualize_predictions(self, df_data, df_results, output_path='./step2_ai_predictions.png'):
        print("\nì‹œê°í™” ìƒì„± ì¤‘...")
        fig, axes = plt.subplots(2, 3, figsize=(20, 12))
        ax1 = axes[0, 0]
        colors = plt.cm.Set3(np.linspace(0, 1, len(df_results)))
        for idx, (_, pig_info) in enumerate(df_results.iterrows()):
            pig_id = pig_info['pig_id']
            pig_data = df_data[df_data['pig_id'] == pig_id].sort_values('day')
            ax1.plot(pig_data['day'], pig_data['weight_kg'], label=f'Pig {pig_id}', color=colors[idx], linewidth=1.5)
        ax1.axhline(y=self.target_weight, color='red', linestyle='--', label=f'Target ({self.target_weight}kg)', linewidth=2)
        ax1.set_xlabel('Day'); ax1.set_ylabel('Weight (kg)'); ax1.set_title('Growth Curves', fontweight='bold')
        ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8); ax1.grid(True, alpha=0.3)
        ax2 = axes[0, 1]
        predicted = df_results[df_results['status'] == 'predicted']
        if len(predicted) > 0:
            x = np.arange(len(predicted)); width = 0.25
            if 'ai_prediction_days' in predicted.columns:
                ax2.bar(x - width, predicted['ai_prediction_days'], width, label='AI', alpha=0.7)
            if 'lstm_prediction_days' in predicted.columns:
                lstm_days = predicted['lstm_prediction_days'].replace('N/A', np.nan).astype(float)
                ax2.bar(x, lstm_days, width, label='LSTM', alpha=0.7)
            if 'stat_prediction_days' in predicted.columns:
                ax2.bar(x + width, predicted['stat_prediction_days'], width, label='Statistical', alpha=0.7)
            ax2.set_xticks(x)
            ax2.set_xticklabels([f'Pig {pid}' for pid in predicted['pig_id']], rotation=45)
            ax2.set_ylabel('Days to Shipment'); ax2.set_title('Prediction Method Comparison', fontweight='bold')
            ax2.legend(); ax2.grid(True, alpha=0.3, axis='y')
        ax3 = axes[0, 2]
        if 'final_days_to_shipment' in df_results.columns:
            valid_days = df_results[df_results['status'] == 'predicted']['final_days_to_shipment']
            if len(valid_days) > 0:
                ax3.hist(valid_days, bins=15, alpha=0.7, edgecolor='black')
                ax3.axvline(x=valid_days.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {valid_days.mean():.0f}d')
                ax3.set_xlabel('Days to Shipment'); ax3.set_ylabel('Frequency'); ax3.set_title('Final Prediction Distribution', fontweight='bold')
                ax3.legend(); ax3.grid(True, alpha=0.3, axis='y')
        ax4 = axes[1, 0]
        if 'ai_daily_gain' in df_results.columns:
            ax4.scatter(df_results['current_weight'], df_results['ai_daily_gain'], c=df_results.index, cmap='viridis', s=100, alpha=0.6)
            ax4.set_xlabel('Current Weight (kg)'); ax4.set_ylabel('AI Predicted Daily Gain (kg/day)'); ax4.set_title('Weight vs AI Predicted Growth Rate', fontweight='bold')
            ax4.grid(True, alpha=0.3)
        ax5 = axes[1, 1]
        y_pos = np.arange(len(df_results))
        days = df_results['final_days_to_shipment'].fillna(0)
        colors_bar = ['green' if d == 0 else 'orange' if d < 30 else 'red' for d in days]
        bars = ax5.barh(y_pos, days, color=colors_bar, alpha=0.7)
        ax5.set_yticks(y_pos)
        ax5.set_yticklabels([f'Pig {pid}' for pid in df_results['pig_id']])
        ax5.set_xlabel('Days to Shipment'); ax5.set_title('Shipment Schedule', fontweight='bold')
        ax5.grid(True, alpha=0.3, axis='x')
        for bar, d in zip(bars, days):
            if d > 0:
                ax5.text(bar.get_width() + 1, bar.get_y() + bar.get_height()/2, f'{int(d)}d', va='center', fontsize=9)
        ax6 = axes[1, 2]
        methods = ['AI', 'LSTM', 'Statistical', 'Ensemble']
        if len(predicted) > 0:
            avg_ai = predicted['ai_prediction_days'].mean() if 'ai_prediction_days' in predicted.columns else 0
            avg_lstm = predicted['lstm_prediction_days'].replace('N/A', np.nan).astype(float).mean()
            avg_lstm = avg_lstm if not np.isnan(avg_lstm) else 0
            avg_stat = predicted['stat_prediction_days'].mean() if 'stat_prediction_days' in predicted.columns else 0
            avg_ensemble = predicted['final_days_to_shipment'].mean()
            values = [avg_ai, avg_lstm, avg_stat, avg_ensemble]
            bars = ax6.bar(methods, values, alpha=0.7, color=['blue', 'green', 'orange', 'red'])
            ax6.set_ylabel('Average Days to Shipment'); ax6.set_title('Average Prediction by Method', fontweight='bold')
            ax6.grid(True, alpha=0.3, axis='y')
            for bar in bars:
                height = bar.get_height()
                ax6.text(bar.get_x() + bar.get_width()/2., height, f'{height:.1f}d', ha='center', va='bottom')
        plt.suptitle('AI/LSTM Hybrid Prediction Results', fontsize=16, fontweight='bold', y=0.995)
        plt.tight_layout()
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        print(f"ê·¸ë˜í”„ ì €ì¥: {output_path}")
        plt.close()

# -----------------------------------------------------------------
# (â˜…ì‹ ê·œâ˜…) ì˜ˆì¸¡ê¸° ë¡œë“œ í•¨ìˆ˜
# -----------------------------------------------------------------
@st.cache_resource
def load_hybrid_predictor():
    """ AI/LSTM/í†µê³„ í•˜ì´ë¸Œë¦¬ë“œ ì˜ˆì¸¡ê¸°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤. """
    try:
        # (AI ë‹´ë‹¹ì ì½”ë“œì˜ target_weight=116 ì‚¬ìš©)
        predictor = HybridPredictor(target_weight=116.0)
        st.success("AI í•˜ì´ë¸Œë¦¬ë“œ ì˜ˆì¸¡ê¸° ë¡œë“œ ì„±ê³µ!")
        return predictor
    except Exception as e:
        st.error(f"í•˜ì´ë¸Œë¦¬ë“œ ì˜ˆì¸¡ê¸° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

# -----------------------------------------------------------------
# 1. DB ì—°ê²° ì„¤ì •
# -----------------------------------------------------------------
def get_db_connection():
    """SQLAlchemy ì—°ê²° ì—”ì§„ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        db_info = st.secrets["database"]
        engine_url = (
            f"mysql+mysqlconnector://{db_info['user']}:{db_info['password']}@"
            f"{db_info['host']}:{db_info['port']}/{db_info['db_name']}"
        )
        engine = sa.create_engine(engine_url, pool_pre_ping=True)
        return engine
    except Exception:
        st.info("DB ë¹„ì‚¬ìš© ëª¨ë“œ: .streamlit/secrets.tomlì˜ [database] ì„¤ì •ì´ ì—†ê±°ë‚˜ ì—°ê²° ì‹¤íŒ¨")
        return None


@st.cache_resource
def init_db_connection():
    """DB ì—°ê²° ì—”ì§„ì„ ì´ˆê¸°í™”í•˜ê³  ë°˜í™˜í•©ë‹ˆë‹¤."""
    return get_db_connection()


# -----------------------------------------------------------------
# 2. ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ë“¤
# -----------------------------------------------------------------
@st.cache_data(ttl=600)
def load_data_from_db(_engine, table_name, limit=1000, order_by_col='timestamp'):
    """DBì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” ë²”ìš© í•¨ìˆ˜ (â˜…ìˆ˜ì •â˜…: ë¸íƒ€ ë¡œì§ ì œê±°, ì›ë˜ëŒ€ë¡œ ë³µì›)"""
    if _engine is None:
        return pd.DataFrame()
    try:
        order_clause = f"ORDER BY {order_by_col} DESC" if order_by_col else ""

        # 'None' ë¬¸ìì—´ì´ ì•„ë‹Œ ì§„ì§œ None íƒ€ì…ìœ¼ë¡œ limit ì²˜ë¦¬
        if limit == 'None' or limit is None:
            limit_clause = ""
        else:
            limit_clause = f"LIMIT {limit}"

        query = f"SELECT * FROM {table_name} {order_clause} {limit_clause}"

        df = pd.read_sql(query, con=_engine)
        if 'timestamp' in df.columns:
            df['timestamp'] = pd.to_datetime(df['timestamp'])
        elif 'fcst_dt' in df.columns:  # ë‚ ì”¨ í…Œì´ë¸”ìš©
            df['fcst_dt'] = pd.to_datetime(df['fcst_dt'])
        elif 'fcst_date' in df.columns:
            df['fcst_date'] = pd.to_datetime(df['fcst_date'])
        return df
    except Exception as e:
        st.error(f"'{table_name}' ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
        return pd.DataFrame()

# -----------------------------------------------------------------
# 3. AI ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜
# -----------------------------------------------------------------
@st.cache_resource
def load_prediction_model(model_path):
    """(ë°©ë²• 1) í•™ìŠµëœ AI ëª¨ë¸ íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    if not os.path.exists(model_path):
        st.warning(f"ëª¨ë¸ íŒŒì¼({model_path})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. AI Mock-up ëª¨ë“œë¡œ ì‘ë™í•©ë‹ˆë‹¤.")
        return None
    try:
        model = joblib.load(model_path)
        return model
    except Exception as e:
        st.error(f"ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


# -----------------------------------------------------------------
# 4. í˜ì´ì§€ ì´ë™(ë“œë¦´ë‹¤ìš´)ì„ ìœ„í•œ í•¨ìˆ˜
# -----------------------------------------------------------------
def set_detail_view(chamber_id, chamber_no):
    st.session_state.view_mode = 'detail'
    st.session_state.selected_chamber_id = chamber_id
    st.session_state.selected_chamber_no = chamber_no


def set_overview_view():
    st.session_state.view_mode = 'overview'
    st.session_state.selected_chamber_id = None
    st.session_state.selected_chamber_no = None


# -----------------------------------------------------------------
# 5. Streamlit ëŒ€ì‹œë³´ë“œ UI êµ¬ì„±
# -----------------------------------------------------------------

st.set_page_config(page_title="ğŸ· ìŠ¤ë§ˆíŠ¸ ì¶•ì‚¬ ëŒ€ì‹œë³´ë“œ", layout="wide")

if 'view_mode' not in st.session_state:
    set_overview_view()

# --- 1. ëª¨ë“  ì›ë³¸ ë°ì´í„° ë¡œë“œ ---
engine = init_db_connection()
# limit ì›ë˜ëŒ€ë¡œ ë³µì›
sensor_df_all = load_data_from_db(engine, 'Chamber_Logs', limit=20000)
equipment_df_all = load_data_from_db(engine, 'Equipment_Logs', limit=20000)
weather_ultra_fcst_df = load_data_from_db(engine, "weather_ultra_fcst", limit=48, order_by_col="fcst_dt")

pig_log_df_all = load_data_from_db(engine, 'Pig_Logs', limit='None', order_by_col='timestamp')
chambers_df = load_data_from_db(engine, 'Chambers', limit='None', order_by_col=None)
pigs_df = load_data_from_db(engine, 'Pigs', limit='None', order_by_col=None)

mid_land_fcst_df = load_data_from_db(
    engine,
    "mid_land_fcst",
    limit=7,
    order_by_col="fcst_date"
)
weather_ultra_fcst_df = load_data_from_db(
    engine,
    "weather_ultra_fcst",
    limit=48,
    order_by_col="fcst_dt"
)

if 'weight_kg' in pig_log_df_all.columns:
    pig_log_df_all['weight_kg'] = pd.to_numeric(pig_log_df_all['weight_kg'], errors='coerce')

if not weather_ultra_fcst_df.empty:
    weather_ultra_fcst_df.columns = [col.upper() for col in weather_ultra_fcst_df.columns]

# -----------------------------------------------------------------
# (ì±”ë²„ 1, 2 ë¼ì§€ 20ë§ˆë¦¬ ìƒ˜í”Œë§ ë¡œì§)
# -----------------------------------------------------------------
CHAMBER_IDS_TO_SAMPLE = [1, 2]  # (Chamber_noê°€ ì•„ë‹Œ chamber_id ê¸°ì¤€)
PIGS_PER_CHAMBER = 20
# ìƒ˜í”Œë§í•  ì±”ë²„ IDì™€ ë§ˆë¦¬ ìˆ˜
if not pigs_df.empty and not pig_log_df_all.empty:

    try:
        # 1. 'ëœë¤ ì‹œë“œ'ê°€ 42ë¡œ ê³ ì •ëœ 'ëœë¤ ìƒì„±ê¸°'ë¥¼ ë§Œë“­ë‹ˆë‹¤.
        rng = np.random.default_rng(42)

        # 2. ìƒ˜í”Œë§í•  ì±”ë²„ì˜ ë¼ì§€ ID ëª©ë¡
        pigs_to_sample_list = []
        for cid in CHAMBER_IDS_TO_SAMPLE:
            pigs_in_chamber = pigs_df[pigs_df['chamber_id'] == cid]['pig_id'].unique()

            # 3. ì±”ë²„ë³„ 20ë§ˆë¦¬ ìƒ˜í”Œë§ (20ë§ˆë¦¬ë³´ë‹¤ ì ìœ¼ë©´ ëª¨ë‘ ì„ íƒ)
            sample_size = min(len(pigs_in_chamber), PIGS_PER_CHAMBER)

            # 4. 'np.random.choice' ëŒ€ì‹ , ì‹œë“œê°€ ê³ ì •ëœ 'rng.choice'ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
            sampled_pig_ids = rng.choice(pigs_in_chamber, size=sample_size, replace=False)
            pigs_to_sample_list.append(sampled_pig_ids)

        # 5. ìƒ˜í”Œë§í•˜ì§€ ì•Šì„ ì±”ë²„(3, 4ë²ˆ)ì˜ ë¼ì§€ ID ëª©ë¡
        pigs_to_keep_ids = pigs_df[~pigs_df['chamber_id'].isin(CHAMBER_IDS_TO_SAMPLE)]['pig_id'].unique()
        pigs_to_sample_list.append(pigs_to_keep_ids)

        # 6. ìµœì¢… ì‚¬ìš©í•  ë¼ì§€ ID ëª©ë¡
        final_pig_ids = np.concatenate(pigs_to_sample_list)

        # 7. 'Pigs' (ë§ˆìŠ¤í„°)ì™€ 'Pig_Logs' (ë¡œê·¸) í…Œì´ë¸” ëª¨ë‘ë¥¼ ì´ ID ëª©ë¡ìœ¼ë¡œ í•„í„°ë§
        pigs_df = pigs_df[pigs_df['pig_id'].isin(final_pig_ids)].copy()
        pig_log_df_all = pig_log_df_all[pig_log_df_all['pig_id'].isin(final_pig_ids)].copy()

    except Exception as e:
        st.error(f"ìƒ˜í”Œë§ ì¤‘ ì˜¤ë¥˜: {e}")

# =================================================================
# A. 'ì „ì²´ ë§µ (Overview)' í™”ë©´
# =================================================================
if st.session_state.view_mode == "overview":

    st.title("ğŸ· ìŠ¤ë§ˆíŠ¸ ì¶•ì‚¬ í˜„í™© (ì „ì²´ ë§µ)")

    with st.container(border=True):
        st.subheader("AICU ì´ê´„ ìš”ì•½")
        cols = st.columns(5)

        if not pig_log_df_all.empty:
            total_pigs = len(pig_log_df_all['pig_id'].unique())
            cols[0].metric("ì´ ì‚¬ìœ¡ ë‘ìˆ˜", f"{total_pigs} ë§ˆë¦¬")
        else:
            cols[0].metric("ì´ ì‚¬ìœ¡ ë‘ìˆ˜", "N/A (ë¡œê·¸ ì—†ìŒ)")

        # 3. 'ì´ ì£¼ì˜ ê°œì²´ ìˆ˜' (ìƒˆë¡œìš´ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°)
        if not pig_log_df_all.empty:
            # (ë°ì´í„° íƒ€ì… ë³€í™˜ ë° ìœ íš¨ ë°ì´í„° í•„í„°ë§)
            try:
                pig_log_df_all['temp_rectal'] = pd.to_numeric(pig_log_df_all['temp_rectal'], errors='coerce')
                pig_log_df_all['breath_rate'] = pd.to_numeric(pig_log_df_all['breath_rate'], errors='coerce')
            except Exception:
                pass  # ì˜¤ë¥˜ ë¬´ì‹œ

            valid_logs = pig_log_df_all.dropna(subset=['temp_rectal', 'breath_rate'])

            if not valid_logs.empty:
                latest_pig_logs = valid_logs.loc[valid_logs.groupby("pig_id")["timestamp"].idxmax()]

                #  AI ê·œì¹™ ì—”ì§„ ì ìš©
                # 1. ê° ë¼ì§€ì˜ ì •ìƒ ì²´ì˜¨ ë²”ìœ„ë¥¼ ê³„ì‚°
                latest_pig_logs['tmin'], latest_pig_logs['tmax'] = zip(
                    *latest_pig_logs['weight_kg'].apply(get_normal_temp_range))

                # 2. (í˜¸í¡ ê¸°ì¤€ì€ 55~70ìœ¼ë¡œ ê°€ì • - í•„ìš”ì‹œ ìˆ˜ì •)
                breath_norm_min = 55
                breath_norm_max = 70

                # 'ì •ìƒ' ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ëŠ” ëª¨ë“  ê°œì²´ í•„í„°ë§
                warning_pigs_total = latest_pig_logs[
                    (latest_pig_logs["temp_rectal"] < latest_pig_logs["tmin"]) |
                    (latest_pig_logs["temp_rectal"] > latest_pig_logs["tmax"]) |
                    (latest_pig_logs["breath_rate"] < breath_norm_min) |
                    (latest_pig_logs["breath_rate"] > breath_norm_max)
                    ]
                cols[1].metric("ì´ 'ì£¼ì˜' ê°œì²´ ìˆ˜", f"{len(warning_pigs_total)} ë§ˆë¦¬")
            else:
                cols[1].metric("ì´ 'ì£¼ì˜' ê°œì²´ ìˆ˜", "N/A (ë°ì´í„° ë¶€ì¡±)")
        else:
            cols[1].metric("ì´ 'ì£¼ì˜' ê°œì²´ ìˆ˜", "N/A (ë¡œê·¸ ì—†ìŒ)")

        # 3. 'í˜„ì¬ ì™¸ë¶€ ë‚ ì”¨' (ì‹œê°„ë³„ DB ë°ì´í„° ì‚¬ìš©)
        if not weather_ultra_fcst_df.empty and {"T1H", "REH"}.issubset(weather_ultra_fcst_df.columns):
            latest_weather = weather_ultra_fcst_df.iloc[0]  # ê°€ì¥ ìµœì‹  ì‹œê°„
            cols[2].metric("í˜„ì¬ ì™¸ë¶€ ì˜¨ë„", f"{latest_weather.get('T1H', 0):.1f} Â°C")
            cols[3].metric("í˜„ì¬ ì™¸ë¶€ ìŠµë„", f"{latest_weather.get('REH', 0):.1f} %")
        else:
            cols[2].metric("í˜„ì¬ ì™¸ë¶€ ì˜¨ë„", "N/A")
            cols[3].metric("í˜„ì¬ ì™¸ë¶€ ìŠµë„", "N/A")

        # 4. 'ì˜¤ëŠ˜ ê°•ìˆ˜ í™•ë¥ ' (ì¼ì¼ ìš”ì•½ DB ë°ì´í„° ì‚¬ìš©)
        if not mid_land_fcst_df.empty and {"pop_am", "pop_pm"}.issubset(mid_land_fcst_df.columns):
            today_weather = mid_land_fcst_df.iloc[0]  # ì˜¤ëŠ˜ ì˜ˆë³´
            pop_am = today_weather.get("pop_am", 0)  # ì˜¤ì „ ê°•ìˆ˜ í™•ë¥ 
            pop_pm = today_weather.get("pop_pm", 0)  # ì˜¤í›„ ê°•ìˆ˜ í™•ë¥ 
            cols[4].metric("ì˜¤ì „/ì˜¤í›„ ê°•ìˆ˜", f"{pop_am}% / {pop_pm}%")
            if (pop_am or 0) > 70 or (pop_pm or 0) > 70:
                st.warning("ğŸš¨ ê°•ìˆ˜ í™•ë¥  70% ì´ìƒ! í™˜ê¸°/ìŠµë„ ê´€ë¦¬ì— ìœ ì˜í•˜ì„¸ìš”.")
        else:
            cols[4].metric("ê°•ìˆ˜ í™•ë¥ ", "N/A")

    # ----------------------------------------------------

    st.divider()
    st.subheader("ì±”ë²„ë³„ í˜„í™© (í´ë¦­í•˜ì—¬ ë“œë¦´ë‹¤ìš´)")

    if chambers_df.empty:
        st.error("ì±”ë²„ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        grid_cols = st.columns(2)

        # (AI ê·œì¹™ì„ ì ìš©í•˜ê¸° ìœ„í•´ 'pig_log_df_all'ì˜ ìœ íš¨í•œ ìµœì‹  ë¡œê·¸ë¥¼ ë¯¸ë¦¬ ê³„ì‚°)
        valid_logs_all = pd.DataFrame()
        if not pig_log_df_all.empty:
            valid_logs_all = pig_log_df_all.dropna(subset=['temp_rectal', 'breath_rate', 'weight_kg'])
            if not valid_logs_all.empty:
                valid_logs_all = valid_logs_all.loc[valid_logs_all.groupby("pig_id")["timestamp"].idxmax()]
                valid_logs_all['tmin'], valid_logs_all['tmax'] = zip(
                    *valid_logs_all['weight_kg'].apply(get_normal_temp_range))

        for i, row in chambers_df.iterrows():
            chamber_id = row['chamber_id']
            chamber_no = row['chamber_no']
            current_col = grid_cols[i % 2]

            warn_count = 0
            if not pigs_df.empty and not valid_logs_all.empty:
                pigs_in_chamber_ids = pigs_df[pigs_df['chamber_id'] == chamber_id]['pig_id']

                latest_logs_chamber = valid_logs_all[valid_logs_all['pig_id'].isin(pigs_in_chamber_ids)]

                if not latest_logs_chamber.empty:
                    # (í˜¸í¡ ê¸°ì¤€ì€ 55~70ìœ¼ë¡œ ê°€ì • - í•„ìš”ì‹œ ìˆ˜ì •)
                    breath_norm_min = 55
                    breath_norm_max = 70

                    warning_pigs_chamber = latest_logs_chamber[
                        (latest_logs_chamber["temp_rectal"] < latest_logs_chamber["tmin"]) |
                        (latest_logs_chamber["temp_rectal"] > latest_logs_chamber["tmax"]) |
                        (latest_logs_chamber["breath_rate"] < breath_norm_min) |
                        (latest_logs_chamber["breath_rate"] > breath_norm_max)
                        ]
                    warn_count = len(warning_pigs_chamber)

            with current_col.container(border=True):

                #'ì£¼ì˜' ë°°ë„ˆ ê¸°ì¤€ ì„¤ì • (5ë§ˆë¦¬ ì´ìƒ)
                warning_threshold_count = 5

                if warn_count >= warning_threshold_count:
                    st.error(f"ğŸš¨ {chamber_no}ë²ˆ ì±”ë²„ (ì£¼ì˜!)")
                else:
                    st.subheader(f" {chamber_no}ë²ˆ ì±”ë²„")

                c1_metric, c2_metric = st.columns(2)
                # (í˜„ì¬ ì˜¨ë„ ë¡œì§)
                chamber_sensor_data = sensor_df_all[sensor_df_all['chamber_id'] == chamber_id]
                if not chamber_sensor_data.empty and "temperature" in chamber_sensor_data.columns:
                    c1_metric.metric("í˜„ì¬ ì˜¨ë„", f"{chamber_sensor_data.iloc[0]['temperature']:.1f} Â°C")
                else:
                    c1_metric.metric("í˜„ì¬ ì˜¨ë„", "N/A")

                c2_metric.metric("ê±´ê°• 'ì£¼ì˜' ê°œì²´", f"{warn_count} ë§ˆë¦¬")

                st.button(
                    f"{chamber_no}ë²ˆ ì±”ë²„ ìƒì„¸ ì •ë³´ ë³´ê¸°",
                    key=f"btn_detail_{chamber_id}",
                    on_click=set_detail_view,
                    args=(chamber_id, chamber_no)
                )
    # ì¼ì¼ ë‚ ì”¨ (ì‹œê°„ë³„ ìƒì„¸ ì˜ˆë³´ DB)
    st.header("ğŸŒ¦ï¸ ì¼ì¼ ë‚ ì”¨")

    # (ëŒ€ë¬¸ìë¡œ ë³€í™˜ëœ ì»¬ëŸ¼ëª… ì‚¬ìš©)
    needed_weather_cols = {"FCST_DT", "T1H", "REH", "RN1", "SKY", "PTY"}

    if not weather_ultra_fcst_df.empty and needed_weather_cols.issubset(weather_ultra_fcst_df.columns):

        weather_chart_data = weather_ultra_fcst_df.set_index("FCST_DT")

        w_tab1, w_tab2, w_tab3 = st.tabs(["ğŸŒ¡ï¸ ê¸°ì˜¨ (T1H)", "ğŸ’§ ìŠµë„ (REH)", "â˜” ì‹œê°„ë‹¹ ê°•ìˆ˜ëŸ‰ (RN1)"])

        with w_tab1:
            st.plotly_chart(px.line(weather_chart_data, y='T1H', title='ì‹œê°„ë³„ ì™¸ë¶€ ê¸°ì˜¨'), width='stretch')
        with w_tab2:
            st.plotly_chart(px.line(weather_chart_data, y='REH', title='ì‹œê°„ë³„ ì™¸ë¶€ ìŠµë„'), width='stretch')
        with w_tab3:
            st.plotly_chart(px.bar(weather_chart_data, y='RN1', title='ì‹œê°„ë³„ ê°•ìˆ˜ëŸ‰'), width='stretch')

        latest_sky = weather_ultra_fcst_df.iloc[0].get("SKY", -1)
        st.info(f"í˜„ì¬ í•˜ëŠ˜ ìƒíƒœ(SKY) ì½”ë“œëŠ” '{latest_sky}'ì…ë‹ˆë‹¤. (1: ë§‘ìŒ, 3: êµ¬ë¦„ë§ìŒ, 4: íë¦¼)")

    else:
        st.warning("ì‹œê°„ë³„ ìƒì„¸ ë‚ ì”¨(weather_ultra_fcst) ë°ì´í„°ë¥¼ DBì—ì„œ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆê±°ë‚˜, í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    st.divider()
    # ('ì£¼ê°„ ë‚ ì”¨ ì˜ˆë³´' í…Œì´ë¸”)
    # ----------------------------------------------------
    st.divider()
    st.subheader("ğŸ—“ï¸ ì£¼ê°„ ë‚ ì”¨ ìš”ì•½ (ê¸°ìƒì²­ DB)")

    # (DBì—ì„œ ë¡œë“œí•œ mid_land_fcst_df ë³€ìˆ˜ ì‚¬ìš©)
    needed_cols = ["fcst_date", "wf_am", "pop_am", "wf_pm", "pop_pm", "tmin", "tmax"]

    if not mid_land_fcst_df.empty and all(col in mid_land_fcst_df.columns for col in needed_cols):

        # 1. ëŒ€ì‹œë³´ë“œì— í‘œì‹œí•  ì»¬ëŸ¼ë§Œ ì„ íƒ
        display_df = mid_land_fcst_df[list(needed_cols)].copy()

        # 2. ë‚ ì§œìˆœìœ¼ë¡œ ì •ë ¬
        display_df = display_df.sort_values(by="fcst_date")

        # 3. ë‚ ì§œ í˜•ì‹ì„ '00ì›” 00ì¼ (ìš”ì¼)'ë¡œ ë³€ê²½
        display_df['fcst_date'] = display_df['fcst_date'].dt.strftime('%mì›” %dì¼ (%a)')

        # 4. ì»¬ëŸ¼ ì´ë¦„ì„ í•œê¸€ë¡œ ë³€ê²½
        display_df = display_df.rename(columns={
            "fcst_date": "ë‚ ì§œ",
            "pop_am": "ì˜¤ì „ í™•ë¥ (%)",
            "wf_am": "ì˜¤ì „ ë‚ ì”¨",
            "pop_pm": "ì˜¤í›„ í™•ë¥ (%)",
            "wf_pm": "ì˜¤í›„ ë‚ ì”¨",
            "tmin": "ìµœì € ê¸°ì˜¨(Â°C)",
            "tmax": "ìµœê³  ê¸°ì˜¨(Â°C)"
        })

        display_df['ì¼ì¼ ê°•ìˆ˜ í™•ë¥ (%)'] = display_df[['ì˜¤ì „ í™•ë¥ (%)', 'ì˜¤í›„ í™•ë¥ (%)']].max(axis=1).astype(int)

        weather_emoji_map = {
            "ë§‘ìŒ": "â˜€ï¸",
            "êµ¬ë¦„ë§ìŒ": "ğŸŒ¥ï¸",
            "íë¦¼": "â˜ï¸",
            "ë¹„": "ğŸŒ§ï¸",
            "ëˆˆ": "â„ï¸",
            "ë¹„/ëˆˆ": "ğŸŒ¨ï¸",
            "ì†Œë‚˜ê¸°": "ğŸŒ¦ï¸"
            # (í•„ìš”ì‹œ DBì— ìˆëŠ” ë‹¤ë¥¸ í…ìŠ¤íŠ¸ë„ ì¶”ê°€)
        }
        # 2. 'ì˜¤ì „ ë‚ ì”¨'ì™€ 'ì˜¤í›„ ë‚ ì”¨' ì»¬ëŸ¼ì˜ í…ìŠ¤íŠ¸ë¥¼ ì´ëª¨í‹°ì½˜ìœ¼ë¡œ ë°”ê¿‰ë‹ˆë‹¤.
        display_df["ì˜¤ì „ ë‚ ì”¨"] = display_df["ì˜¤ì „ ë‚ ì”¨"].replace(weather_emoji_map)
        display_df["ì˜¤í›„ ë‚ ì”¨"] = display_df["ì˜¤í›„ ë‚ ì”¨"].replace(weather_emoji_map)

        final_column_order = [
            "ë‚ ì§œ",
            "ì¼ì¼ ê°•ìˆ˜ í™•ë¥ (%)",
            "ì˜¤ì „ ë‚ ì”¨",
            "ì˜¤í›„ ë‚ ì”¨",
            "ìµœì € ê¸°ì˜¨(Â°C)",
            "ìµœê³  ê¸°ì˜¨(Â°C)",
        ]
        display_df = display_df[final_column_order]
        # 5. 'ë‚ ì§œ'ë¥¼ ì¸ë±ìŠ¤ë¡œ ì„¤ì •í•˜ì—¬ í…Œì´ë¸”(í‘œ)ë¡œ í‘œì‹œ
        st.dataframe(
            display_df.set_index("ë‚ ì§œ"),
            width='stretch'
        )

    else:
        st.warning("ì£¼ê°„ ë‚ ì”¨ ìš”ì•½(mid_land_fcst) ë°ì´í„°ë¥¼ DBì—ì„œ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆê±°ë‚˜, í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

# =================================================================
# B. 'ì±”ë²„ ìƒì„¸ (Detail)' í™”ë©´
# =================================================================
elif st.session_state.view_mode == 'detail':

    st.button("â—€ ì „ì²´ ë§µìœ¼ë¡œ ëŒì•„ê°€ê¸°", on_click=set_overview_view)
    selected_id = st.session_state.selected_chamber_id
    selected_no = st.session_state.selected_chamber_no
    st.title(f"ğŸ· {selected_no}ë²ˆ ì±”ë²„ ìƒì„¸ ì •ë³´")

    sensor_df_filtered = sensor_df_all[sensor_df_all['chamber_id'] == selected_id]
    equipment_df_filtered = equipment_df_all[equipment_df_all['chamber_id'] == selected_id]

    pig_log_df_filtered = pd.DataFrame()
    if not pigs_df.empty:
        pigs_in_chamber = pigs_df[pigs_df['chamber_id'] == selected_id]['pig_id']
        pig_log_df_filtered = pig_log_df_all[pig_log_df_all['pig_id'].isin(pigs_in_chamber)].copy()

    st.divider()

    st.header("ğŸ“ˆ í˜„ì¬ ì±”ë²„ ìƒí™©")
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("ğŸ“Š í™˜ê²½ ì„¼ì„œ (Chamber_Logs)")
        if not sensor_df_filtered.empty:
            latest_sensor = sensor_df_filtered.iloc[0]
            c1, c2, c3 = st.columns(3)
            #ê°€ì§œ ë¸íƒ€ ì œê±°
            c1.metric("ì˜¨ë„", f"{latest_sensor['temperature']:.1f} Â°C")
            c2.metric("ìŠµë„", f"{latest_sensor['humidity']:.1f} %")
            c3.metric("CO2", f"{latest_sensor['co2']:.0f} ppm")

            min_date = sensor_df_filtered['timestamp'].min().date()
            max_date = sensor_df_filtered['timestamp'].max().date()

            date_range = st.date_input(
                "ì¡°íšŒ ê¸°ê°„ì„ ì„ íƒí•˜ì„¸ìš”:",
                value=(min_date, max_date), min_value=min_date, max_value=max_date,
                key=f"date_selector_{selected_id}"
            )

            chart_data_filtered_by_date = pd.DataFrame()
            if len(date_range) == 2:
                start_date = pd.to_datetime(date_range[0])
                end_date = pd.to_datetime(date_range[1]) + pd.Timedelta(days=1) - pd.Timedelta(seconds=1)
                chart_data_filtered_by_date = sensor_df_filtered[
                    (sensor_df_filtered['timestamp'] >= start_date) &
                    (sensor_df_filtered['timestamp'] <= end_date)
                    ]

            if chart_data_filtered_by_date.empty:
                st.info("ì„ íƒëœ ê¸°ê°„ì— í•´ë‹¹í•˜ëŠ” ì„¼ì„œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                tab1_chart, tab2_chart, tab3_chart = st.tabs(["ğŸŒ¡ï¸ ì˜¨ë„", "ğŸ’§ ìŠµë„", "ğŸ’¨ CO2"])
                with tab1_chart:
                    fig_temp = px.line(chart_data_filtered_by_date, x='timestamp', y='temperature', title='ì˜¨ë„ ì¶”ì´')
                    st.plotly_chart(fig_temp, width='stretch')
                with tab2_chart:
                    fig_humi = px.line(chart_data_filtered_by_date, x='timestamp', y='humidity', title='ìŠµë„ ì¶”ì´')
                    st.plotly_chart(fig_humi, width='stretch')
                with tab3_chart:
                    fig_co2 = px.line(chart_data_filtered_by_date, x='timestamp', y='co2', title='CO2 ì¶”ì´')
                    st.plotly_chart(fig_co2, width='stretch')

        else:
            st.warning("ì„¼ì„œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    with col2:
        st.subheader("â¤ï¸ ë¼ì§€ ê±´ê°• ìƒíƒœ (Pig_Logs)")

        # (Pig_Logs ë°ì´í„°ê°€ í•„í„°ë§ë˜ì–´ 'pig_log_df_filtered'ì— ìˆë‹¤ê³  ê°€ì •)
        if not pig_log_df_filtered.empty:

            # 1. ìœ íš¨í•œ ê±´ê°• ë°ì´í„° í•„í„°ë§
            valid_health_logs = pig_log_df_filtered.dropna(subset=['temp_rectal', 'breath_rate', 'weight_kg'])

            if not valid_health_logs.empty:
                # 2. ê° ë¼ì§€ì˜ ê°€ì¥ ìµœì‹  ë¡œê·¸ ê°€ì ¸ì˜¤ê¸°
                latest_pig_logs = valid_health_logs.loc[valid_health_logs.groupby('pig_id')['timestamp'].idxmax()]

                # 3. AI ê·œì¹™ ì—”ì§„ ì ìš©
                latest_pig_logs['tmin'], latest_pig_logs['tmax'] = zip(
                    *latest_pig_logs['weight_kg'].apply(get_normal_temp_range))

                # 4. (í˜¸í¡ ê¸°ì¤€ì€ 55~70ìœ¼ë¡œ ê°€ì • - í•„ìš”ì‹œ ìˆ˜ì •)
                breath_norm_min = 55
                breath_norm_max = 70

                # 5. 'ì •ìƒ' ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ëŠ” ëª¨ë“  ê°œì²´ í•„í„°ë§
                warning_pigs = latest_pig_logs[
                    (latest_pig_logs['temp_rectal'] < latest_pig_logs["tmin"]) |  # ì˜¨ë„ ë‚®ìŒ
                    (latest_pig_logs['temp_rectal'] > latest_pig_logs["tmax"]) |  # ì˜¨ë„ ë†’ìŒ
                    (latest_pig_logs['breath_rate'] < breath_norm_min) |  # í˜¸í¡ ëŠë¦¼
                    (latest_pig_logs['breath_rate'] > breath_norm_max)  # í˜¸í¡ ë¹ ë¦„
                    ]

                st.metric("ê±´ê°• 'ì£¼ì˜' ê°œì²´ ìˆ˜", f"{len(warning_pigs)} ë§ˆë¦¬")

                if len(warning_pigs) > 0:
                    with st.expander("'ì£¼ì˜' ê°œì²´ ëª©ë¡ ë³´ê¸°"):

                        # 6. 'ì£¼ì˜ ì›ì¸'ì„ AI ê·œì¹™ ê¸°ì¤€ìœ¼ë¡œ ë³€ê²½
                        def find_reason(row):
                            reasons = []
                            tmin, tmax = row['tmin'], row['tmax']  # (AIê°€ ê³„ì‚°í•œ ë²”ìœ„)
                            # ì˜¨ë„ í™•ì¸
                            if row['temp_rectal'] < tmin:
                                reasons.append(f"ì˜¨ë„ ë‚®ìŒ ({row['temp_rectal']:.1f}Â°C)")
                            elif row['temp_rectal'] > tmax:
                                reasons.append(f"ì˜¨ë„ ë†’ìŒ ({row['temp_rectal']:.1f}Â°C)")

                            # í˜¸í¡ í™•ì¸
                            if row['breath_rate'] < breath_norm_min:
                                reasons.append(f"í˜¸í¡ ëŠë¦¼ ({row['breath_rate']:.0f}íšŒ)")
                            elif row['breath_rate'] > breath_norm_max:
                                reasons.append(f"í˜¸í¡ ë¹ ë¦„ ({row['breath_rate']:.0f}íšŒ)")

                            return ', '.join(reasons)


                        warning_pigs_with_reason = warning_pigs.copy()
                        warning_pigs_with_reason['ì£¼ì˜ ì›ì¸'] = warning_pigs_with_reason.apply(find_reason, axis=1)

                        display_cols = ["pig_id", "weight_kg", "temp_rectal", "breath_rate", "ì£¼ì˜ ì›ì¸"]
                        st.dataframe(warning_pigs_with_reason[display_cols])
            else:
                st.warning("ìœ íš¨í•œ ê±´ê°• ë°ì´í„°(ì²´ì˜¨/í˜¸í¡ìˆ˜/ì²´ì¤‘)ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.warning("ë¼ì§€ ë¡œê·¸ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    st.divider()

    # --- ì„¹ì…˜ 3: ì¶œí•˜ ë° ì—ë„ˆì§€ ë¶„ì„ ---
    st.header("ğŸ– ì¶œí•˜ ë° ì—ë„ˆì§€ ë¶„ì„")
    tab1, tab2 = st.tabs(["ì¶œí•˜ ë‚ ì§œ ì˜ˆì¸¡", "ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ë¶„ì„"])

    with tab1:
        # 1. ì•± ì‹œì‘ ì‹œ ë¡œë“œí•œ 'í•˜ì´ë¸Œë¦¬ë“œ ì˜ˆì¸¡ê¸°'ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        predictor = load_hybrid_predictor()

        target_weight = st.number_input(
            "ëª©í‘œ ì¶œí•˜ ì²´ì¤‘(kg)ì„ ì…ë ¥í•˜ì„¸ìš”:",
            min_value=80.0, value=116.0, step=1.0,
            help="ì´ ì²´ì¤‘ì„ ê¸°ì¤€ìœ¼ë¡œ ì¶œí•˜ ê°€ëŠ¥ ê°œì²´ ìˆ˜ì™€ ì˜ˆì¸¡ ë‚ ì§œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."
        )
        if predictor is not None:
            predictor.target_weight = target_weight

        if not pig_log_df_filtered.empty and predictor is not None:

            # (ë°ì´í„° ë³‘í•© ë° AI ì…ë ¥ìš© ë°ì´í„° ìƒì„±)
            feed_data_df = sensor_df_filtered[['timestamp', 'feed_volume']].dropna()
            pig_data_merged = pd.merge(
                pig_log_df_filtered,
                feed_data_df,
                on="timestamp",
                how="left"
            )
            pig_data_for_ai = pig_data_merged.rename(columns={
                'weight_kg': 'weight_kg',
                'feed_volume': 'feed_intake_kg',
                'pig_id': 'pig_id'
            })
            if 'day' not in pig_data_for_ai.columns:
                pig_data_for_ai = pig_data_for_ai.sort_values(by=['pig_id', 'timestamp'])
                pig_data_for_ai['day'] = pig_data_for_ai.groupby('pig_id')['timestamp'].transform(
                    lambda x: (x - x.min()).dt.days)
            if 'daily_gain_kg' not in pig_data_for_ai.columns:
                pig_data_for_ai['weight_lag1'] = pig_data_for_ai.groupby('pig_id')['weight_kg'].shift(1)
                pig_data_for_ai['daily_gain_kg'] = pig_data_for_ai['weight_kg'] - pig_data_for_ai['weight_lag1']
                pig_data_for_ai['daily_gain_kg'] = pig_data_for_ai['daily_gain_kg'].fillna(0.6)

            # ----------------------------------------------------

            logs_with_weights = (
                pig_data_for_ai.dropna(subset=["weight_kg"])
                if "weight_kg" in pig_data_for_ai.columns else pd.DataFrame()
            )

            if not logs_with_weights.empty:
                latest_weights = logs_with_weights.loc[
                    logs_with_weights.groupby("pig_id")["timestamp"].idxmax()
                ]
                ship_ready_now = latest_weights[latest_weights["weight_kg"] >= target_weight]

                c1, c2 = st.columns(2)
                c1.metric(f"í˜„ì¬ {target_weight}kg ì´ìƒ (ì¶œí•˜ ê°€ëŠ¥)", f"{len(ship_ready_now)} ë§ˆë¦¬")
                pigs_below = latest_weights[latest_weights["weight_kg"] < target_weight]
                c2.metric("ì¶œí•˜ ì˜ˆì¸¡ ëŒ€ìƒ", f"{len(pigs_below)} ë§ˆë¦¬")
                st.divider()

                st.subheader(f"ğŸ· {target_weight}kg ë„ë‹¬ ë‚ ì§œ ì˜ˆì¸¡ (AI í•˜ì´ë¸Œë¦¬ë“œ)")

                if not pigs_below.empty:

                    results = []
                    today = pd.Timestamp.now()

                    with st.spinner(f"{len(pigs_below)}ë§ˆë¦¬ ì „ì²´ì— ëŒ€í•œ ì¶œí•˜ ì˜ˆì¸¡ì„ ê³„ì‚° ì¤‘ì…ë‹ˆë‹¤... (ì‹œê°„ ì†Œìš”)"):
                        # (LSTM ëª¨ë¸ì€ ëª¨ë“  ë¼ì§€ ë°ì´í„°ë¡œ 1íšŒ í›ˆë ¨ í•„ìš”)
                        predictor.train_lstm_on_data(logs_with_weights)

                        for _, rep_pig in pigs_below.iterrows():
                            pig_id = rep_pig["pig_id"]
                            current_weight = rep_pig["weight_kg"]

                            pig_data_hist = logs_with_weights[logs_with_weights['pig_id'] == pig_id]

                            prediction_result_df = predictor.predict_shipment(pig_data_hist)

                            if not prediction_result_df.empty:
                                pred_row = prediction_result_df.iloc[0]

                                # 1. 'results' ë¦¬ìŠ¤íŠ¸ì— 4ê°œì˜ í•µì‹¬ ì •ë³´ë§Œ ì €ì¥í•©ë‹ˆë‹¤.
                                results.append({
                                    'ë¼ì§€ ID': pig_id,
                                    'í˜„ì¬ ì²´ì¤‘(kg)': round(current_weight, 1),
                                    'ë‚¨ì€ ì¼ìˆ˜(ì¼)': int(pred_row['final_days_to_shipment']),
                                    'ì˜ˆìƒ ì¶œí•˜ ë‚ ì§œ': pred_row['predicted_shipment_date']
                                })

                    if results:
                        # 6. ì˜ˆì¸¡ ê²°ê³¼ í…Œì´ë¸”(DataFrame) ìƒì„±
                        result_df = pd.DataFrame(results).sort_values('ë‚¨ì€ ì¼ìˆ˜(ì¼)')

                        fastest_pig = result_df.iloc[0]
                        st.metric(
                            f"ê°€ì¥ ë¹ ë¥¸ ì˜ˆìƒ ì¶œí•˜ì¼ (ID: {fastest_pig['ë¼ì§€ ID']})",
                            f"{fastest_pig['ì˜ˆìƒ ì¶œí•˜ ë‚ ì§œ']}",
                            f"{fastest_pig['ë‚¨ì€ ì¼ìˆ˜(ì¼)']}ì¼ ë‚¨ìŒ"
                        )

                        with st.expander("ì „ì²´ ê°œì²´ë³„ ì˜ˆìƒ ì¶œí•˜ì¼ ë³´ê¸° (ë¹ ë¥¸ ìˆœ)"):
                            #2. 'result_df' (4ê°œ ì»¬ëŸ¼ë§Œ ìˆìŒ)ë¥¼ ì¸ë±ìŠ¤ ì„¤ì • í›„ ë°”ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.
                            st.dataframe(result_df.set_index('ë¼ì§€ ID'), width='stretch')
                    else:
                        st.error("AI ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

                else:
                    st.success(f"ë°ì´í„°ê°€ ìˆëŠ” ëª¨ë“  ê°œì²´ê°€ ì´ë¯¸ ëª©í‘œ ì²´ì¤‘({target_weight}kg) ì´ìƒì…ë‹ˆë‹¤.")
            else:
                st.warning("ì´ ì±”ë²„ì—ëŠ” í˜„ì¬ ìœ íš¨í•œ ì²´ì¤‘ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.warning("ëª¸ë¬´ê²Œ ë°ì´í„°ê°€ ì—†ê±°ë‚˜ AI ì˜ˆì¸¡ê¸°ë¥¼ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    with tab2:
        if not equipment_df_filtered.empty:
            min_date_eq = equipment_df_filtered['timestamp'].min().date()
            max_date_eq = equipment_df_filtered['timestamp'].max().date()

            date_range_eq = st.date_input(
                "ì¡°íšŒ ê¸°ê°„ì„ ì„ íƒí•˜ì„¸ìš”:",
                value=(min_date_eq, max_date_eq),
                min_value=min_date_eq,
                max_value=max_date_eq,
                key=f"energy_date_selector_{selected_id}"
            )

            energy_data_filtered_by_date = pd.DataFrame()
            start_date_str = min_date_eq.isoformat()
            end_date_str = max_date_eq.isoformat()

            if len(date_range_eq) == 2:
                start_date = pd.to_datetime(date_range_eq[0])
                end_date = pd.to_datetime(date_range_eq[1]) + pd.Timedelta(days=1) - pd.Timedelta(seconds=1)
                start_date_str = date_range_eq[0].isoformat()
                end_date_str = date_range_eq[1].isoformat()

                energy_data_filtered_by_date = equipment_df_filtered[
                    (equipment_df_filtered['timestamp'] >= start_date) &
                    (equipment_df_filtered['timestamp'] <= end_date)
                    ]

            if energy_data_filtered_by_date.empty:
                st.info("ì„ íƒëœ ê¸°ê°„ì— í•´ë‹¹í•˜ëŠ” ì—ë„ˆì§€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.subheader(f"ê¸°ê°„ ë‚´ ì¥ë¹„ë³„ ì‚¬ìš©ëŸ‰ ({start_date_str} ~ {end_date_str})")
                period_usage = energy_data_filtered_by_date.groupby('equipment_type')['power_usage_wh'].sum() / 1000
                fig_energy_period = px.bar(period_usage, title="ì¥ë¹„ë³„ ê¸°ê°„ ë‚´ ì‚¬ìš©ëŸ‰ (kWh)",
                                           labels={'value': 'ì‚¬ìš©ëŸ‰ (kWh)', 'equipment_type': 'ì¥ë¹„ ì¢…ë¥˜'})
                st.plotly_chart(fig_energy_period, width='stretch')

                st.divider()


                @st.cache_data
                def convert_df_to_csv(df):
                    return df.to_csv(index=False, encoding='utf-8-sig')


                csv_data = convert_df_to_csv(energy_data_filtered_by_date)

                st.download_button(
                    label=f"ğŸ“ˆ ê¸°ê°„({start_date_str}~{end_date_str}) ë¡œê·¸ ë‹¤ìš´ë¡œë“œ",
                    data=csv_data,
                    file_name=f"energy_logs_{selected_no}ch_{start_date_str}_to_{end_date_str}.csv",
                    mime="text/csv",
                )
        else:
            st.warning("ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.divider()
